{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries if not already installed\n",
    "# !pip install pandas numpy langchain faiss-cpu scikit-learn\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from langchain.document_loaders import CSVLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the generated datasets\n",
    "user_data = pd.read_csv(\"../data/user_data.csv\")\n",
    "booking_history = pd.read_csv(\"../data/booking_history.csv\")\n",
    "train_schedule = pd.read_csv(\"../data/train_schedule.csv\")\n",
    "pricing_data = pd.read_csv(\"../data/pricing_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Data: (5, 6)\n",
      "Booking History: (100, 7)\n",
      "Train Schedule: (100, 7)\n",
      "Pricing Data: (100, 6)\n"
     ]
    }
   ],
   "source": [
    "# Display dataset shapes\n",
    "print(f\"User Data: {user_data.shape}\")\n",
    "print(f\"Booking History: {booking_history.shape}\")\n",
    "print(f\"Train Schedule: {train_schedule.shape}\")\n",
    "print(f\"Pricing Data: {pricing_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------\n",
    "# Step 1: Data Preprocessing\n",
    "# -------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge booking history with user data\n",
    "df = booking_history.merge(user_data, on=\"User ID\", how=\"left\")\n",
    "\n",
    "# Merge with train schedule (using Train Name)\n",
    "df = df.merge(train_schedule, left_on=\"Train Name\", right_on=\"Train Name\", how=\"left\")\n",
    "\n",
    "# Merge with pricing data on Train Name & Class\n",
    "df = df.merge(pricing_data, on=\"Train Name\", how=\"left\")\n",
    "\n",
    "# Merge with transaction data using User ID\n",
    "df = df.merge(transaction_data, on=\"User ID\", how=\"left\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=[\"Date\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Fill missing values\n",
    "df.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Ensure all expected columns exist before applying Label Encoding\n",
    "available_categorical_features = [col for col in [\n",
    "    \"Gender\", \"Location\", \"Preferred Class\", \"Loyalty Status\",\n",
    "    \"Train Name\", \"Departure\", \"Arrival\", \"Seat Preference\", \"Payment Method\"\n",
    "] if col in df.columns]  # Check existence before applying encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "\n",
    "for feature in available_categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "    label_encoders[feature] = le\n",
    "\n",
    "# Convert numerical columns to float before normalization\n",
    "numerical_features = [\"Age\", \"Ticket Price\", \"Base Price\", \"Surge Price\", \"Final Price\", \"Duration (hrs)\"]\n",
    "\n",
    "for col in numerical_features:\n",
    "    if col in df.columns:  # Ensure column exists before applying transformation\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")  # Convert to float, setting errors='coerce' will handle bad data\n",
    "        df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())  # Normalize\n",
    "\n",
    "# Convert all columns to string for embedding processing\n",
    "df[\"combined_features\"] = df.astype(str).agg(\" \".join, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# Step 2: Create LangChain Embeddings\n",
    "# ---------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LangChain OpenAI Embeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Convert text data to embeddings\n",
    "train_data = df[\"combined_features\"].tolist()\n",
    "embeddings = embedding_model.embed_documents(train_data)\n",
    "\n",
    "# Create FAISS index for similarity search\n",
    "vector_store = FAISS.from_embeddings(embeddings)\n",
    "\n",
    "# Save the FAISS index\n",
    "vector_store.save_local(\"../deployment/faiss_index\")\n",
    "\n",
    "print(\"Model training complete. FAISS index saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------\n",
    "# Step 3: Model Testing (Simple Recommendation)\n",
    "# ---------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommend_tickets(user_input):\n",
    "    \"\"\"\n",
    "    Function to recommend train tickets based on user query.\n",
    "    \"\"\"\n",
    "    input_embedding = embedding_model.embed_query(user_input)\n",
    "    similar_docs = vector_store.similarity_search_by_vector(input_embedding, k=5)\n",
    "\n",
    "    recommendations = [doc.metadata for doc in similar_docs]\n",
    "    return recommendations\n",
    "\n",
    "# Example test\n",
    "sample_user_query = \"Business class ticket from CityA to CityB with a window seat\"\n",
    "recommendations = recommend_tickets(sample_user_query)\n",
    "\n",
    "print(\"\\nTop Recommended Tickets:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
