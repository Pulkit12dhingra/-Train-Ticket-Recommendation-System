{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas numpy torch transformers langchain fastapi uvicorn\n",
    "#%pip install --upgrade langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Done! Sample Data:\n",
      "                                 User ID   Train Name Departure Arrival  \\\n",
      "0  b3d5de0a-f350-4fc2-a5e8-1005a9864d7f    Superfast     CityC   CityH   \n",
      "1  b3d5de0a-f350-4fc2-a5e8-1005a9864d7f      Express     CityC   CityB   \n",
      "2  4d4d8ff3-7b7a-4191-814c-c3c079b01211    Intercity     CityC   CityD   \n",
      "3  b3d5de0a-f350-4fc2-a5e8-1005a9864d7f     Regional     CityC   CityH   \n",
      "4  b2549fa9-b299-48e0-b0f5-7a4f3811048b  Night Train     CityE   CityF   \n",
      "\n",
      "         Date  Ticket Price  Seat Preference  Age Gender  \\\n",
      "0  2024-12-27      0.021574                1   59   Male   \n",
      "1  2024-11-12      0.875484                1   59   Male   \n",
      "2  2024-11-19      0.418606                0   51   Male   \n",
      "3  2024-09-07      0.179963                1   59   Male   \n",
      "4  2024-10-29      0.052849                0   37  Other   \n",
      "\n",
      "               Location  Preferred Class Loyalty Status  \n",
      "0          Mercadoshire                0         Bronze  \n",
      "1          Mercadoshire                0         Bronze  \n",
      "2        East Lindaport                2         Bronze  \n",
      "3          Mercadoshire                0         Bronze  \n",
      "4  Port Jacquelinemouth                2       Platinum  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "# Load Data\n",
    "booking_data = pd.read_csv(\"data/booking_history.csv\")\n",
    "user_data = pd.read_csv(\"data/user_data.csv\")\n",
    "\n",
    "# Merge datasets\n",
    "data = booking_data.merge(user_data, on=\"User ID\", how=\"left\")\n",
    "\n",
    "# Convert categorical features into numerical encoding\n",
    "data[\"Preferred Class\"] = data[\"Preferred Class\"].astype(\"category\").cat.codes\n",
    "data[\"Seat Preference\"] = data[\"Seat Preference\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Normalize ticket prices\n",
    "data[\"Ticket Price\"] = (data[\"Ticket Price\"] - data[\"Ticket Price\"].min()) / (\n",
    "    data[\"Ticket Price\"].max() - data[\"Ticket Price\"].min()\n",
    ")\n",
    "\n",
    "print(\"Preprocessing Done! Sample Data:\\n\", data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "# Load a pre-trained text classification model\n",
    "MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"  # Replace with a fine-tuned recommender model if available\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5, ignore_mismatched_sizes=True)\n",
    "\n",
    "# Define function to get ticket recommendations\n",
    "def recommend_ticket(user_id):\n",
    "    # Extract user details\n",
    "    user_info = data[data[\"User ID\"] == user_id].iloc[0]\n",
    "    \n",
    "    # Generate input text for recommendation\n",
    "    input_text = f\"User prefers {user_info['Preferred Class']} class and {user_info['Seat Preference']} seat. \\\n",
    "                   Previous booking was {user_info['Train Name']} with price {user_info['Ticket Price']}.\"\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # Predict ticket category\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits).item()\n",
    "\n",
    "    # Return recommended train ticket category\n",
    "    categories = [\"Budget\", \"Standard\", \"Business\", \"Luxury\", \"Sleeper\"]\n",
    "    return f\"Recommended Ticket Category: {categories[prediction]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import LLMResult\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "class TrainTicketLLM(LLM):\n",
    "    \"\"\"Custom LLM for recommending train tickets using Hugging Face model\"\"\"\n",
    "\n",
    "    def _call(self, prompt: str, stop=None) -> str:\n",
    "        user_id = prompt.strip()\n",
    "        return recommend_ticket(user_id)\n",
    "\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom_train_ticket_recommender\"\n",
    "\n",
    "# Instantiate the LLM\n",
    "llm = TrainTicketLLM()\n",
    "\n",
    "# LangChain-powered Recommendation System\n",
    "def get_ticket_recommendation(user_id):\n",
    "    return llm(user_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [64167]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:64540 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64540 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64540 - \"GET / HTTP/1.1\" 404 Not Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [64167]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "\n",
    "# Apply nest_asyncio to allow running FastAPI inside Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Import recommendation function\n",
    "#from recommend_system import recommend_ticket  \n",
    "\n",
    "@app.get(\"/recommend/{user_id}\")\n",
    "async def get_recommendation(user_id: str):\n",
    "    ticket_recommendation = recommend_ticket(user_id)\n",
    "    return {\"user_id\": user_id, \"recommendation\": ticket_recommendation}\n",
    "\n",
    "# Run FastAPI inside Jupyter Notebook\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
